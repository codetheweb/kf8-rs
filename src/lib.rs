use nom::{
    branch::alt,
    bytes::complete::{tag, take, take_while},
    character::complete::{alphanumeric1, char},
    combinator::map,
    error::ErrorKind,
    multi::count,
    number::complete::{be_u16, be_u24, be_u32, be_u64, be_u8, le_u32},
    sequence::tuple,
    IResult,
};
use std::{
    iter::once,
    str::{self, FromStr},
};

use crate::constants::{MainLanguage, SubLanguage};

#[macro_use]
extern crate lazy_static;

mod constants;

#[derive(Debug, PartialEq)]
pub struct SectionHeader {
    offset: u32,
    flags: u8,
    val: u32,
}

#[derive(Debug, PartialEq)]
enum MobiHeaderIdent {
    BookMobi,
    TextRead,
}

#[derive(Debug, PartialEq)]
enum CompressionType {
    None,
    PalmDoc,
    HuffCdic,
}

fn parse_compression_type(input: &[u8]) -> IResult<&[u8], CompressionType> {
    alt((
        map(tag([0x00, 0x01]), |_| CompressionType::None),
        map(tag([0x00, 0x02]), |_| CompressionType::PalmDoc),
        map(tag([0x44, 0x48]), |_| CompressionType::HuffCdic),
    ))(input)
}

#[derive(Debug, PartialEq)]
pub struct MobiHeader {
    name: String,
    num_sections: u16,
    ident: MobiHeaderIdent,
    section_headers: Vec<SectionHeader>,
}

fn parse_name(input: &[u8]) -> IResult<&[u8], String> {
    let (input, name_bytes) = take(32usize)(input)?;

    let name = map(take_while(|b| b != 0x00), |bytes| {
        // todo: should conditionally be utf8 or cp1252 based on codec in header
        str::from_utf8(bytes).unwrap_or_default().to_string()
    })(name_bytes)?;

    Ok((input, name.1))
}

fn parse_ident(input: &[u8]) -> IResult<&[u8], MobiHeaderIdent> {
    alt((tag("BOOKMOBI"), tag("TEXTREAD")))(input).map(|(input, ident)| {
        let ident = match ident {
            b"BOOKMOBI" => MobiHeaderIdent::BookMobi,
            b"TEXTREAD" => MobiHeaderIdent::TextRead,
            _ => unreachable!(),
        };
        (input, ident)
    })
}

fn parse_section_header(input: &[u8]) -> IResult<&[u8], SectionHeader> {
    let (input, (offset, flags, val)) = tuple((be_u32, be_u8, be_u24))(input)?;
    Ok((input, SectionHeader { offset, flags, val }))
}

fn parse_mobi_header(input: &[u8]) -> IResult<&[u8], MobiHeader> {
    let (input, header) = take(72usize)(input)?;
    let (input, _) = take(4usize)(input)?;
    let (input, num_sections) = be_u16(input)?;

    if num_sections == 0 {
        todo!("should return error")
    }

    let (_, name) = parse_name(header)?;
    let (_, ident) = parse_ident(&header[0x3C..])?;

    let (mut input, mut section_headers) = (input, Vec::new());
    for _ in 0..num_sections {
        let (i, section_header) = parse_section_header(input)?;
        section_headers.push(section_header);
        input = i;
    }

    Ok((
        input,
        MobiHeader {
            name,
            num_sections,
            ident,
            section_headers,
        },
    ))
}

#[derive(Debug, PartialEq)]
enum Codepage {
    Cp1252,
    Utf8,
}

fn parse_codepage(input: &[u8]) -> IResult<&[u8], Codepage> {
    alt((
        map(tag([0x00, 0x00, 0x04, 0xe4]), |_| Codepage::Cp1252),
        map(tag([0x00, 0x00, 0xfd, 0xe9]), |_| Codepage::Utf8),
    ))(input)
}

// Some KF8 files have header length == 264 (generated by kindlegen 2.9?). See https://bugs.launchpad.net/bugs/1179144
// We choose 500 for future versions of kindlegen
const MAX_HEADER_LENGTH: usize = 500;

const NULL_INDEX: u32 = u32::MAX;

#[derive(Debug, PartialEq)]
struct BookHeader {
    compression_type: CompressionType,
    records: u16,
    records_size: u16,
    // todo: enum?
    encryption_type: u16,
    // todo: enum?
    doctype: String,
    fdstidx: u32,
    // todo: enum/split up?
    extra_flags: u16,
}

impl BookHeader {
    fn sizeof_trailing_section_entries(&self, section_data: &[u8]) -> usize {
        let mut num = 0;
        let size = section_data.len();
        let mut flags = self.extra_flags >> 1;

        fn sizeof_trailing_section_entry(section_data: &[u8], offset: usize) -> usize {
            let mut offset = offset;
            let mut bitpos = 0;
            let mut result: usize = 0;

            loop {
                let v = section_data[offset - 1] as usize;
                result |= (v & 0x7f) << bitpos;
                bitpos += 7;
                offset -= 1;

                if (v & 0x80) != 0 || (bitpos >= 28) || offset == 0 {
                    return result;
                }
            }
        }

        while flags > 0 {
            if flags & 1 > 0 {
                num += sizeof_trailing_section_entry(section_data, size - num);
            }

            flags >>= 1;
        }

        if self.extra_flags & 1 > 0 {
            let offset = size - num - 1;
            num += (section_data[offset] as usize & 0x3) + 1;
        }

        num
    }
}

fn parse_book_header<'a>(
    input: &'a [u8],
    mobi_header: &MobiHeader,
) -> IResult<&'a [u8], BookHeader> {
    let total_remaining_input_length = input.len();

    let (input, compression_type) = parse_compression_type(input)?;
    let (input, _) = take(6usize)(input)?; // Skip 6 bytes
    let (input, records) = be_u16(input)?;
    let (input, records_size) = be_u16(input)?;
    let (input, encryption_type) = be_u16(input)?;

    println!("Compression Type: {:?}", compression_type);
    println!("Records: {:?}", records);
    println!("Records Size: {:?}", records_size);
    println!("Encryption Type: {:?}", encryption_type);

    let (input, _) = take(2usize)(input)?; // Skip 2 bytes
    let (input, doctype) = take(4usize)(input)?;

    // 20 bytes past input

    println!(
        "Doc Type: {:?}",
        str::from_utf8(doctype).unwrap_or_default()
    );
    // todo: assert on doc type?

    // todo: handle cp1252?

    let (input, length) = be_u32(input)?;
    let (input, type_field) = be_u32(input)?;
    let (input, codepage) = parse_codepage(input)?;
    let (input, unique_id) = be_u32(input)?;
    let (input, version) = be_u32(input)?;

    // 40 bytes past input

    println!("Length: {:?}", length);
    println!("Type: {:?}", type_field);
    println!("Codepage: {:?}", codepage);
    println!("Unique ID: {:?}", unique_id);
    println!("Version: {:?}", version);

    if codepage == Codepage::Cp1252 {
        // todo: return error/handle cp1252
        panic!("cp1252 not supported")
    }

    let (input, _) = take(52usize)(input)?; // Skip 52 bytes

    let (input, langcode) = be_u32(input)?;
    println!("Langcode: {:?}", langcode);

    let langid = langcode & 0xff;
    let sublangid = (langcode >> 10) & 0xff;

    // todo: don't unwrap
    let language = MainLanguage::try_from(langid).unwrap();
    let sublanguage = SubLanguage::try_from(sublangid).unwrap();

    println!("Language: {:?}", language);
    println!("Sublanguage: {:?}", sublanguage);

    let (input, _) = take(8usize)(input)?; // Skip 8 bytes

    let (input, mobi_version) = be_u32(input)?;

    println!("Mobi Version: {:?}", mobi_version);

    let (input, first_image_index) = be_u32(input)?;

    println!("First Image Index: {:?}", first_image_index);

    let (input, _) = take(16usize)(input)?; // Skip 12 bytes

    let (input, exth_flag) = be_u32(input)?;
    // todo: exth parsing (extended header, mostly DRM?)
    println!("EXTH Flag: {:?}", exth_flag);

    // at 132 bytes past input

    let should_skip_extra_flag = mobi_header.ident == MobiHeaderIdent::TextRead
        || length < 0xe4
        || length > MAX_HEADER_LENGTH as u32;
    let mut extra_flags = 0;

    let (input, skelidx, dividx, othidx, fdstidx, datpidx, fdstcnt) =
        if mobi_version == 8 && total_remaining_input_length >= (0xf8 + 16) {
            let (input, _) = take(60usize)(input)?; // Skip 60 bytes

            let (input, (mut fdstidx, fdstcnt)) = tuple((be_u32, be_u32))(input)?;
            let (input, _) = take(42usize)(input)?; // Skip 42 bytes

            println!(
                "consumed bytes: {} {}",
                total_remaining_input_length - input.len(),
                should_skip_extra_flag
            );

            let input = if should_skip_extra_flag {
                take(6usize)(input)?.0
            } else {
                let (input, flags) = be_u16(input)?;
                extra_flags = flags;

                println!("read flags: {}", flags);

                // Skip 4 bytes
                take(4usize)(input)?.0
            };

            let (input, (dividx, skelidx, datpidx, othidx)) =
                tuple((be_u32, be_u32, be_u32, be_u32))(input)?;

            if fdstcnt <= 1 {
                fdstidx = NULL_INDEX;
            }

            (input, skelidx, dividx, othidx, fdstidx, datpidx, fdstcnt)
        } else {
            // todo: read extra flag

            (
                input, NULL_INDEX, NULL_INDEX, NULL_INDEX, NULL_INDEX, NULL_INDEX, NULL_INDEX,
            )
        };

    println!("skelidx: {:?}", skelidx);
    println!("dividx: {:?}", dividx);
    println!("othidx: {:?}", othidx);
    println!("fdstidx: {:?}", fdstidx);
    println!("datpidx: {:?}", datpidx);
    println!("fdstcnt: {:?}", fdstcnt);

    println!("Extra Flags: {:?}", extra_flags);

    Ok((
        input,
        BookHeader {
            compression_type,
            records,
            records_size,
            doctype: String::from_utf8(doctype.to_vec()).unwrap(),
            encryption_type,
            fdstidx,
            extra_flags,
        },
    ))
}

#[derive(Debug, PartialEq)]
pub struct MobiBook {
    mobi_header: MobiHeader,
    content: String,
}

fn parse_book(input: &[u8]) -> IResult<&[u8], MobiBook> {
    let original_input = input;
    let original_input_length = input.len();
    let (input, mobi_header) = parse_mobi_header(input)?;

    let (input, _) = take(2usize)(input)?; // Skip 2 bytes

    // todo: use first section offset instead of manually skipping bytes above?
    let (_, book_header) = parse_book_header(
        &original_input[mobi_header.section_headers.first().unwrap().offset as usize..],
        &mobi_header,
    )?;

    fn get_section_data<'a>(
        data: &'a [u8],
        mobi_header: &MobiHeader,
        section_i: usize,
    ) -> &'a [u8] {
        let end_offset = if section_i == (mobi_header.num_sections - 1).into() {
            data.len()
        } else {
            mobi_header.section_headers[section_i + 1].offset as usize
        };

        let section_header = &mobi_header.section_headers[section_i];

        &data[section_header.offset as usize..end_offset]
    }

    let mut raw_ml = Vec::new();
    for (i, section_header) in mobi_header.section_headers.iter().enumerate().skip(1) {
        if i > book_header.records as usize {
            break;
        }

        let section_data = get_section_data(original_input, &mobi_header, i);
        let section_data = &section_data
            [..section_data.len() - book_header.sizeof_trailing_section_entries(section_data)];

        let decompressed = palmdoc_compression::calibre::decompress(section_data);

        raw_ml.extend_from_slice(&decompressed);
    }

    let fdst_section_data =
        get_section_data(original_input, &mobi_header, book_header.fdstidx as usize);

    let (_, fdst_table) = parse_fdst(fdst_section_data, raw_ml.len()).unwrap();

    let mut flows = Vec::new();

    for (starts_at, ends_at) in fdst_table.iter().zip(fdst_table.iter().skip(1)) {
        let flow = &raw_ml[*starts_at..*ends_at];
        flows.push(flow);
    }

    let text = flows.first().unwrap();

    println!(
        "flows: {:?}",
        String::from_utf8_lossy(flows[flows.len() - 3])
    );

    Ok((
        input,
        MobiBook {
            mobi_header,
            content: String::from_utf8(raw_ml).unwrap(),
        },
    ))
}

fn parse_fdst(input: &[u8], raw_ml_len: usize) -> IResult<&[u8], Vec<usize>> {
    let (input, _) = tag(b"FDST")(input)?;
    let (input, _) = take(4usize)(input)?;
    let (input, num_sections) = be_u32(input)?;
    let (input, sections) = count(be_u32, num_sections as usize * 2)(input)?;

    let positions = sections
        .iter()
        .step_by(2)
        .map(|x| *x as usize)
        .chain(once(raw_ml_len))
        .collect();

    Ok((input, positions))
}

#[cfg(test)]
mod tests {
    use std::io::{Read, Write};

    use super::*;

    #[test]
    fn extract_raw_html() {
        let mut reader = std::fs::File::open("resources/war_and_peace.azw3").unwrap();
        let mut data = Vec::new();
        reader.read_to_end(&mut data).unwrap();

        let (_, book) = parse_book(&data).unwrap();

        let mut expected_html_reader =
            std::fs::File::open("resources/war_and_peace.rawml").unwrap();
        let mut expected_html = String::new();
        expected_html_reader
            .read_to_string(&mut expected_html)
            .unwrap();

        assert_eq!(book.content, expected_html);
    }
}
